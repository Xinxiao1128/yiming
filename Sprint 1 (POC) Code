Google colab link: https://colab.research.google.com/drive/1O_bYJLG3ydt2nmVM6Eu5zik10gxz__Fv?authuser =1 

from google.colab import drive
drive.mount('/content/drive')

%cd /content/drive/MyDrive/42174_AI_Studio-yiming/Datasets/

import zipfile
import os
import random
from PIL import Image
import matplotlib.pyplot as plt

# Setting the path
zip_path = '/content/drive/MyDrive/42174_AI_Studio-yiming/Datasets/archive.zip'
extract_path = "/content/extracted"

# Decompress the zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"✅Decompression is complete and the files are decompressed to: {extract_path}")

# Search all image files (supports jpg, jpeg, png)
image_folder = extract_path
image_files = []
for root, dirs, files in os.walk(image_folder):
    for file in files:
        if file.lower().endswith(('.jpg', '.jpeg', '.png')):
            image_files.append(os.path.join(root, file))

print(f"Total number of found images: {len(image_files)}")

# Randomly select 3 images
if image_files:
    selected_images = random.sample(image_files, min(3, len(image_files)))
    plt.figure(figsize=(12, 4))
    for i, img_path in enumerate(selected_images):
        img = Image.open(img_path)
        plt.subplot(1, 3, i+1)
        plt.imshow(img)
        plt.title(f"Image {i+1}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()
else:
    print("Image file not found!")

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split

from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.layers import Rescaling

# The correct path
train_path = "/content/extracted/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train"
val_path = "/content/extracted/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid"

img_size = (256, 256)
batch_size = 32

# Loading the training and validation sets
train_gen = image_dataset_from_directory(
    train_path,
    image_size=img_size,
    batch_size=batch_size,
    shuffle=True
)

val_gen = image_dataset_from_directory(
    val_path,
    image_size=img_size,
    batch_size=batch_size,
    shuffle=False
)

# Normalised pixel
rescale = Rescaling(1./255)
train_gen = train_gen.map(lambda x, y: (rescale(x), y))
val_gen = val_gen.map(lambda x, y: (rescale(x), y))

from tensorflow import keras

model = keras.Sequential([
    keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(256, 256, 3)),
    keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),

    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),

    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),
    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),

    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(38, activation='softmax')
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

epochs = 10

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=epochs
)

import numpy as np
import itertools
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay

# Generate predicted values and true labels
predictions = []
true_labels = []

for batch_x, batch_y in val_gen:
  preds = model.predict(batch_x)
  predictions.extend(np.argmax(preds, axis=1))
  true_labels.extend(batch_y.numpy())

# Output evaluation indicators
print("Accuracy : {:.2f}%".format(accuracy_score(true_labels, predictions) * 100))
print("Precision : {:.2f}%".format(precision_score(true_labels, predictions, average='micro') * 100))
print("Recall : {:.2f}%".format(recall_score(true_labels, predictions, average='micro') * 100))

# Confusion matrix
cm = confusion_matrix(true_labels, predictions)
fig, ax = plt.subplots(figsize=(12, 12))
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(ax=ax, cmap='YlGnBu', colorbar=False)
plt.title("Confusion Matrix")
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(20,5))

# Loss curve
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

# Accuracy curve
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.tight_layout()
plt.show()

# Save model
model.save("model_resnet50_trained.h5")
print("✅The model is saved！")

# Print classification report
from sklearn.metrics import classification_report
import os

# Class name
class_dirs = [d for d in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, d))]
class_names = sorted(class_dirs)  # Alphabetical order

print("Classification report：")
print(classification_report(true_labels, predictions, target_names=class_names))

# Displays the predicted image
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

# Create a new small dataset for visualisation
viz_dataset = tf.keras.utils.image_dataset_from_directory(
    val_path,
    image_size=img_size,
    batch_size=6,
    shuffle=True
)

# Standardising images
rescale = Rescaling(1./255)
viz_dataset = viz_dataset.map(lambda x, y: (rescale(x), y))

# Get some data
for images, labels in viz_dataset.take(1):
    # Predicted results
    predictions_batch = model.predict(images)
    predicted_classes = np.argmax(predictions_batch, axis=1)

    # Display of images and predicted results
    plt.figure(figsize=(12, 6))
    for i in range(min(6, len(images))):
        plt.subplot(2, 3, i+1)
        plt.imshow(images[i])
        true_class = class_names[labels[i]]
        predicted_class = class_names[predicted_classes[i]]
        title = f"True: {true_class}\nPred: {predicted_class}"
        plt.title(title)
        plt.axis("off")
    plt.tight_layout()
    plt.show()
